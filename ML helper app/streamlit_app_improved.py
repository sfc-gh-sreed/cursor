import streamlit as st
import pandas as pd
from snowflake.snowpark.context import get_active_session
import json
from typing import Dict, List
import base64

# Get the active Snowflake session
session = get_active_session()

# Page configuration
st.set_page_config(
    page_title="ML Workload Discovery Assistant",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 2rem;
    }
    .recommendation-box {
        background-color: #f8f9fa;
        border-left: 5px solid #1f4e79;
        padding: 1.5rem;
        margin: 1rem 0;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .success-story {
        background-color: #d1f2eb;
        border: 1px solid #52c788;
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .platform-tag {
        background-color: #e3f2fd;
        color: #1976d2;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-weight: bold;
        margin: 0.2rem;
        display: inline-block;
    }
    .limitation-warning {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Hardcoded reference data from the AI & ML 101 and Customer Stories content
CUSTOMER_STORIES = {
    "sagemaker": [
        {
            "title": "Scene+ - 66% Processing Time Reduction with Feature Store",
            "summary": "Migrated from extensive Python scripts to Snowflake Feature Store, achieving 66% reduction in processing time with just 4 blocks of code vs extensive scripts",
            "metrics": "66% processing time reduction, 4 blocks of code vs extensive Python scripts",
            "quote": "Leveraging the straightforward Snowflake Feature Store drove a 66% reduction in processing time; we can join the model universe with the features with just four blocks of code."
        },
        {
            "title": "Unnamed Customer - SageMaker vs Snowflake ML Comparison",
            "summary": "Development time reduced from 2 weeks to 0 setup, production deployment from 3 weeks to <1 hour",
            "metrics": "2-3 weeks setup ‚Üí 0 setup, 3 weeks production ‚Üí <1 hour, 1 day changes ‚Üí <1 hour",
            "quote": "Faster and cheaper dev to production for ML workflows in Snowflake"
        }
    ],
    "databricks": [
        {
            "title": "IGS Energy - 75% Cost Savings, Databricks Migration", 
            "summary": "Migrated from hundreds of thousands of individual models in Databricks to one unified model in Snowflake",
            "metrics": "75% cost savings in training, 30 minutes ‚Üí minutes for hundreds of thousands of customer forecasts",
            "quote": "We can more easily build predictive models and mock up data products all in the Snowflake ecosystem because the data is all there."
        },
        {
            "title": "Decile - 9.2x Speed Improvement, Spark to Snowflake ML",
            "summary": "Customer Data + Analytics Platform migrated from managed Spark to Snowflake ML",
            "metrics": "9.2x speedup (60 minutes to 6.5 minutes), intuitive SKLearn/XGBoost APIs",
            "quote": "By bringing familiar modeling capabilities to Snowflake, Snowpark ML has enabled us to more rapidly iterate on our models, improving accuracy and operational efficiency."
        },
        {
            "title": "Spark New Zealand - 9.2x Performance & Complexity Elimination",
            "summary": "End-to-end marketing analytics migration from Spark infrastructure to Snowflake ML",
            "metrics": "9.2x speed improvement vs Spark, eliminated complex deployment pipelines",
            "quote": "Eliminate complexity, optimize performance, streamlined methodology eliminates necessity for intricate deployment pipelines"
        }
    ],
    "azure": [
        {
            "title": "S&P Global - 75% Time Savings",
            "summary": "Migration from PySpark on Databricks to Snowflake ML", 
            "metrics": "75% time savings moving from PySpark to Snowflake ML",
            "quote": "Significant time savings by moving from PySpark on Databricks to Snowflake ML"
        }
    ],
    "excel": [
        {
            "title": "SpartanNash - Retail Forecasting Automation",
            "summary": "Automated year-long sales forecasting for 183 locations, replacing manual Excel process",
            "metrics": "Accuracy improved 71% ‚Üí 88%, 5,200 hours/year ‚Üí 5 minutes/week automated",
            "quote": "We've been using Snowflake's ML-based forecasting function for three months now and have saved hours of effort while generating more accurate forecasts."
        }
    ],
    "general": [
        {
            "title": "Fidelity Investments - Massive Feature Engineering Performance",
            "summary": "Feature engineering performance improvements across large datasets",
            "metrics": "77x speedup (MinMax Scaler), 50x speedup (One Hot Encoding), 17x speedup (Pearson Correlation)",
            "quote": "Language of choice on a single platform, scalability without operational complexity, no governance trade-offs"
        },
        {
            "title": "Cloudbeds - 95% Accuracy with 24x Training Speed", 
            "summary": "Hospitality performance forecasting across 20,000 global properties",
            "metrics": "95% forecasting accuracy, 30-minute experiments (down from 12+ hours), 5 experiments/day (up from 3/week)",
            "quote": "Accelerated experimentation cycles, achieving 95% accuracy and efficiency gains of over 90% within a six-month forecasting window"
        }
    ]
}

COMPETITIVE_ANALYSIS = {
    "sagemaker": {
        "strengths": ["'Mature' ML platform in capabilities and product marketing", "No gaps in ML features or tools", "Sticky ecosystem"],
        "weaknesses": ["Not really a single platform - must stitch services together", "Architecture complexity to get model off ground", "Forced data movement & egress costs"],
        "snowflake_wins": ["Emphasize architecture simplicity", "Reduce time to value by starting and ending in Snowflake", "Land & Expand in ML pipeline", "If predictions come back to Snowflake, use our model registry"]
    },
    "databricks": {
        "strengths": ["'Industry Leading' in ML mindshare", "Robust MLOps framework/experimentation", "Made for ML practitioners (lots of horsepower)"],
        "weaknesses": ["Overwhelming and complex depending on ML maturity", "Spark experience required, cluster optimization needed", "Lack of cost transparency for ML projects start to finish"],
        "snowflake_wins": ["Grab attention with specific capability showcases", "Snowflake ML jobs for remote code execution", "Position multi-modal offerings - AI SQL + Snowflake ML"]
    },
    "azure": {
        "strengths": ["Really good for all-in Microsoft ecosystem customers", "Tightly integrated to Microsoft services/Databricks", "Mature ML platform for practitioners"],
        "weaknesses": ["Effectively single cloud when it comes to Azure ML", "Using both Databricks ML and Azure ML creates separation confusion", "Delta lake can add complexity and governance challenges"],
        "snowflake_wins": ["If delta lake users proud of 'open source', challenge Azure-centric stack", "Pitch multi-cloud capabilities", "Find pain points/governance challenges in bronze layer", "Land & Expand strategy"]
    }
}

def check_permissions():
    """Check if we have necessary permissions"""
    try:
        # Test basic session access
        result = session.sql("SELECT CURRENT_ROLE(), CURRENT_WAREHOUSE()").collect()
        
        # Test Cortex AI access
        cortex_test = session.sql("""
            SELECT SNOWFLAKE.CORTEX.SUMMARIZE('This is a simple test for Cortex AI access.')
        """).collect()
        
        return True, "All permissions OK"
    except Exception as e:
        return False, str(e)

def process_uploaded_file(uploaded_file):
    """Process uploaded file using Snowflake PARSE_DOCUMENT"""
    try:
        if uploaded_file.type == "text/plain":
            return str(uploaded_file.read(), "utf-8")
        elif uploaded_file.type == "application/pdf":
            # Encode file content to base64 for PARSE_DOCUMENT
            file_content = uploaded_file.read()
            encoded_content = base64.b64encode(file_content).decode('utf-8')
            
            # Use Snowflake PARSE_DOCUMENT
            result = session.sql(f"""
                SELECT SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
                    TO_BINARY('{encoded_content}', 'BASE64'),
                    {{
                        'mode': 'ELEMENTS'
                    }}
                ) as parsed_content
            """).collect()
            
            if result:
                parsed_data = json.loads(result[0]['PARSED_CONTENT'])
                # Extract text from parsed elements
                text_content = ""
                for element in parsed_data:
                    if element.get('type') == 'text':
                        text_content += element.get('content', '') + "\n"
                return text_content
            else:
                return "Failed to parse PDF document"
        else:
            return f"File type {uploaded_file.type} uploaded successfully. Content would be processed using Snowflake PARSE_DOCUMENT."
    except Exception as e:
        return f"Error processing file: {str(e)}"

def detect_platforms(content: str) -> List[str]:
    """Detect multiple ML platforms mentioned in content"""
    content_lower = content.lower()
    platforms = []
    
    # Check for specific platforms
    if any(term in content_lower for term in ["sagemaker", "aws sagemaker", "amazon sagemaker"]):
        platforms.append("AWS SageMaker")
    if any(term in content_lower for term in ["databricks", "spark", "delta lake"]):
        platforms.append("Databricks")
    if any(term in content_lower for term in ["azure ml", "azure machine learning", "microsoft azure"]):
        platforms.append("Azure ML")
    if any(term in content_lower for term in ["vertex ai", "google cloud", "gcp", "vertex"]):
        platforms.append("Google Vertex AI")
    if any(term in content_lower for term in ["excel", "spreadsheet", "manual", "csv files"]):
        platforms.append("Excel/Manual")
    if any(term in content_lower for term in ["jupyter", "notebooks", "local", "python scripts"]):
        platforms.append("Local/Custom")
    
    return platforms if platforms else ["Unknown"]

def analyze_with_cortex(content: str) -> Dict:
    """Enhanced analysis using Snowflake Cortex AI"""
    try:
        if len(content) < 50:
            return {
                'summary': "Content too short for meaningful analysis",
                'platforms': ["Unknown"],
                'recommendations': "Please provide more detailed customer information including current ML platform, pain points, and use cases.",
                'key_takeaways': ["Insufficient content for analysis"]
            }
        
        # Detect platforms
        platforms = detect_platforms(content)
        
        # Use AI_COMPLETE with SUMMARIZE for enhanced analysis
        analysis_prompt = f"""
        Analyze this customer discovery information and provide insights for a Snowflake Account Executive:

        Customer Content: {content}

        Please provide:
        1. A concise summary of the customer's current situation
        2. 3-4 key takeaways about their ML challenges and opportunities
        3. Specific pain points that Snowflake ML could address
        
        Keep the response professional and sales-focused.
        """
        
        analysis_result = session.sql(f"""
            SELECT SNOWFLAKE.CORTEX.COMPLETE(
                'mistral-large',
                '{analysis_prompt.replace("'", "''")}'
            ) as analysis
        """).collect()
        
        # Generate summary using SUMMARIZE
        summary_result = session.sql(f"""
            SELECT SNOWFLAKE.CORTEX.SUMMARIZE('{content.replace("'", "''")}') as summary
        """).collect()
        
        # Extract key takeaways from AI_COMPLETE response
        ai_analysis = analysis_result[0]['ANALYSIS'] if analysis_result else ""
        basic_summary = summary_result[0]['SUMMARY'] if summary_result else "Analysis completed"
        
        # Generate platform-specific recommendations
        recommendations = generate_recommendations(platforms, content, ai_analysis)
        
        # Extract key takeaways from AI analysis
        key_takeaways = extract_key_takeaways(ai_analysis, content)
        
        return {
            'summary': basic_summary,
            'ai_analysis': ai_analysis,
            'platforms': platforms,
            'recommendations': recommendations,
            'key_takeaways': key_takeaways
        }
    except Exception as e:
        return {
            'summary': f"Analysis error: {str(e)}",
            'ai_analysis': f"Unable to complete AI analysis: {str(e)}",
            'platforms': ["Unknown"],
            'recommendations': "Unable to generate recommendations due to technical issues",
            'key_takeaways': ["Analysis failed due to technical issues"]
        }

def generate_recommendations(platforms: List[str], content: str, ai_analysis: str) -> str:
    """Generate specific recommendations based on detected platforms and content"""
    recommendations = []
    
    for platform in platforms:
        if platform == "AWS SageMaker":
            recommendations.extend([
                "**Architecture Simplification**: Highlight how Snowflake ML eliminates the need to stitch together multiple AWS services",
                "**Data Movement Elimination**: Emphasize cost savings from eliminating S3 ‚Üî Snowflake data transfers", 
                "**Time to Value**: Demonstrate 0 setup time vs weeks of SageMaker configuration",
                "**Reference Story**: Share Scene+ success (66% processing time reduction)"
            ])
        elif platform == "Databricks":
            recommendations.extend([
                "**Spark Complexity Elimination**: Position Snowflake ML as Spark-free alternative", 
                "**Cost Transparency**: Emphasize predictable pricing vs unpredictable DBU costs",
                "**Operational Simplicity**: Highlight managed infrastructure vs cluster optimization",
                "**Reference Story**: Share IGS Energy success (75% cost savings, Databricks migration)"
            ])
        elif platform == "Azure ML":
            recommendations.extend([
                "**Multi-Cloud Strategy**: Position Snowflake as cloud-agnostic alternative",
                "**Governance Simplification**: Address Delta Lake complexity concerns",
                "**Unified Platform**: Eliminate confusion between Azure ML and Databricks ML"
            ])
        elif platform == "Excel/Manual":
            recommendations.extend([
                "**ML Functions Approach**: Recommend SQL-based ML Functions for easy adoption",
                "**Automation Benefits**: Highlight time savings and accuracy improvements", 
                "**Reference Story**: Share SpartanNash success (71% ‚Üí 88% accuracy, 5,200 hrs ‚Üí 5 min)"
            ])
    
    if not recommendations:
        recommendations = [
            "**Platform Assessment**: Conduct detailed discovery of current ML infrastructure",
            "**Use Case Identification**: Map specific ML use cases to Snowflake ML capabilities", 
            "**POC Planning**: Design proof-of-concept based on highest-impact use case"
        ]
    
    return "\n".join([f"{i+1}. {rec}" for i, rec in enumerate(recommendations[:6])])

def extract_key_takeaways(ai_analysis: str, content: str) -> List[str]:
    """Extract key takeaways from AI analysis and content"""
    takeaways = []
    
    # Look for specific indicators in content
    content_lower = content.lower()
    
    if "cost" in content_lower or "$" in content:
        takeaways.append("üí∞ **Cost Optimization Opportunity**: Customer has significant infrastructure costs that could be reduced")
    
    if any(term in content_lower for term in ["complex", "difficult", "challenge", "problem"]):
        takeaways.append("üîß **Complexity Reduction**: Customer struggling with operational complexity")
        
    if any(term in content_lower for term in ["data movement", "data transfer", "egress"]):
        takeaways.append("üìä **Data Movement Elimination**: Opportunity to eliminate data transfer costs")
        
    if any(term in content_lower for term in ["governance", "compliance", "audit", "lineage"]):
        takeaways.append("üõ°Ô∏è **Governance Enhancement**: Customer needs better ML governance and compliance")
        
    if any(term in content_lower for term in ["time to production", "deployment", "development"]):
        takeaways.append("‚ö° **Faster Time to Production**: Opportunity to accelerate ML deployment cycles")
    
    # Add platform-specific takeaways
    if "databricks" in content_lower:
        takeaways.append("üéØ **Databricks Displacement**: Strong opportunity for competitive displacement")
    elif "sagemaker" in content_lower:
        takeaways.append("üéØ **SageMaker Displacement**: AWS platform consolidation opportunity")
    
    return takeaways[:4] if takeaways else ["üìà **ML Modernization**: Customer ready for ML platform evolution"]

def get_relevant_stories(platforms: List[str]) -> List[Dict]:
    """Get relevant customer stories based on detected platforms"""
    stories = []
    
    for platform in platforms:
        platform_key = platform.lower().replace(" ", "").replace("/", "")
        if "sagemaker" in platform_key or "aws" in platform_key:
            stories.extend(CUSTOMER_STORIES.get("sagemaker", []))
        elif "databricks" in platform_key:
            stories.extend(CUSTOMER_STORIES.get("databricks", []))
        elif "azure" in platform_key:
            stories.extend(CUSTOMER_STORIES.get("azure", []))
        elif "excel" in platform_key or "manual" in platform_key:
            stories.extend(CUSTOMER_STORIES.get("excel", []))
    
    # Add general stories if no specific platform matches
    if not stories:
        stories.extend(CUSTOMER_STORIES.get("general", []))
    
    # Remove duplicates and limit to 3 stories
    seen_titles = set()
    unique_stories = []
    for story in stories:
        if story['title'] not in seen_titles:
            unique_stories.append(story)
            seen_titles.add(story['title'])
    
    return unique_stories[:3]

def generate_next_steps(platforms: List[str], content: str) -> List[str]:
    """Generate specific, actionable next steps"""
    steps = []
    content_lower = content.lower()
    
    # Platform-specific next steps
    if "Databricks" in platforms:
        steps.extend([
            "Schedule **Databricks vs Snowflake ML cost comparison** workshop",
            "Identify **highest-cost Databricks workload** for POC migration analysis",
            "Prepare **Spark complexity elimination** business case presentation"
        ])
    elif "AWS SageMaker" in platforms:
        steps.extend([
            "Conduct **SageMaker architecture assessment** to identify integration pain points",
            "Demonstrate **unified platform benefits** with specific customer use case",
            "Calculate **data movement cost savings** with Snowflake ML"
        ])
    elif "Excel/Manual" in platforms:
        steps.extend([
            "Design **ML Functions proof-of-concept** using customer's actual data",
            "Show **forecasting accuracy improvements** with live demonstration",
            "Plan **pilot deployment** timeline and success metrics"
        ])
    
    # Timeline-based steps
    if any(term in content_lower for term in ["quarter", "q1", "q2", "q3", "q4", "urgent", "timeline"]):
        steps.append("Create **accelerated evaluation timeline** to meet customer decision deadline")
    
    # Business-focused steps
    if any(term in content_lower for term in ["cfo", "budget", "cost", "roi"]):
        steps.append("Prepare **detailed ROI analysis** with cost comparison vs current platform")
    
    if any(term in content_lower for term in ["team", "scientist", "engineer", "developer"]):
        steps.append("Arrange **technical deep-dive session** with customer's data science team")
    
    # Default steps if none above apply
    if not steps:
        steps = [
            "Conduct **detailed discovery session** to map all current ML use cases",
            "Identify **highest-impact pilot opportunity** for quick win demonstration",
            "Develop **migration strategy** with phased approach and success metrics"
        ]
    
    return steps[:4]

def main():
    """Main application function"""
    
    # Header
    st.markdown('<h1 class="main-header">ü§ñ ML Workload Discovery Assistant</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; color: #666; font-size: 1.2rem;">AI-powered tool to help Snowflake AEs discover and capture ML opportunities</p>', unsafe_allow_html=True)
    
    # Check permissions first
    permissions_ok, perm_message = check_permissions()
    
    if not permissions_ok:
        st.error(f"Permission Issue: {perm_message}")
        st.markdown("""
        ### üîß **Troubleshooting Steps:**
        
        1. **Run diagnostic SQL** from `troubleshoot_permissions.sql`
        2. **Contact your Snowflake admin** to grant Cortex AI permissions
        3. **Verify Cortex AI availability** in your account
        
        ### üìã **Required Permissions:**
        ```sql
        GRANT USAGE ON FUNCTION SNOWFLAKE.CORTEX.SUMMARIZE TO ROLE YOUR_ROLE;
        GRANT USAGE ON FUNCTION SNOWFLAKE.CORTEX.COMPLETE TO ROLE YOUR_ROLE;
        GRANT USAGE ON FUNCTION SNOWFLAKE.CORTEX.PARSE_DOCUMENT TO ROLE YOUR_ROLE;
        ```
        """)
        return
    
    st.success("‚úÖ Permissions verified! App ready to use.")
    
    # Sidebar navigation
    st.sidebar.title("Navigation")
    page = st.sidebar.selectbox(
        "Choose a page",
        ["üìä Customer Analysis", "‚ÑπÔ∏è About"]
    )
    
    if page == "üìä Customer Analysis":
        st.markdown("### üìù Customer Discovery Analysis")
        
        # Input methods
        input_method = st.radio(
            "Choose input method:",
            ["üìù Text Input", "üìÑ Document Upload"]
        )
        
        customer_content = ""
        
        if input_method == "üìù Text Input":
            customer_content = st.text_area(
                "Paste customer discovery notes, meeting transcripts, or pain points:",
                height=300,
                placeholder="""Example:
Customer: DataFlow Analytics - $500M ARR B2B SaaS
Current Platform: Databricks Premium on AWS
Pain Points: Monthly bill went from $80K to $220K in 6 months, data scientists spend 40% time on Spark optimization
Use Cases: Supply chain demand forecasting, inventory optimization, anomaly detection  
Team: 25-person data science team, struggling with cluster management
Timeline: Evaluating alternatives through Q1 2025, CFO mandate to reduce costs by 30%
Decision Criteria: Predictable pricing, faster time to production, better governance
                """)
        
        elif input_method == "üìÑ Document Upload":
            uploaded_file = st.file_uploader(
                "Upload customer documents (PDF, TXT, DOCX)",
                type=['txt', 'pdf', 'docx'],
                help="Upload discovery notes, RFP responses, or customer presentations"
            )
            
            if uploaded_file is not None:
                with st.spinner("Processing document with Snowflake PARSE_DOCUMENT..."):
                    customer_content = process_uploaded_file(uploaded_file)
                    st.success(f"Document processed: {uploaded_file.name}")
        
        # Analysis button
        if st.button("üîç Analyze with Cortex AI", type="primary"):
            if customer_content and len(customer_content.strip()) > 10:
                with st.spinner("Analyzing with Snowflake Cortex AI..."):
                    analysis = analyze_with_cortex(customer_content)
                    
                    # Display results
                    st.markdown("### üìã Analysis Results")
                    
                    # Key Takeaways (enhanced)
                    st.markdown("#### üéØ Key Takeaways")
                    for takeaway in analysis["key_takeaways"]:
                        st.markdown(f"- {takeaway}")
                    
                    # Platform Detection (improved)
                    st.markdown("#### üîç Platform Analysis")
                    
                    # Show detected platforms with better formatting
                    if analysis["platforms"] and analysis["platforms"] != ["Unknown"]:
                        st.markdown("**Detected ML Platforms:**")
                        platform_html = ""
                        for platform in analysis["platforms"]:
                            platform_html += f'<span class="platform-tag">{platform}</span>'
                        st.markdown(platform_html, unsafe_allow_html=True)
                        
                        # Show supported platforms for competitive analysis
                        supported_platforms = ["AWS SageMaker", "Databricks", "Azure ML"]
                        unsupported = [p for p in analysis["platforms"] if p not in supported_platforms and p != "Unknown"]
                        if unsupported:
                            st.markdown(f"""
                            <div class="limitation-warning">
                            <strong>‚ö†Ô∏è Platform Analysis Limitation:</strong> Detailed competitive analysis currently supports AWS SageMaker, Databricks, and Azure ML. 
                            Other platforms detected ({', '.join(unsupported)}) will receive general recommendations.
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.markdown("**Platform Detection:** Unable to identify specific ML platform from provided information")
                    
                    # Enhanced Summary
                    st.markdown("#### üìã Executive Summary")
                    st.markdown(f'<div class="recommendation-box">{analysis["summary"]}</div>', unsafe_allow_html=True)
                    
                    # AI Analysis (new)
                    if analysis.get("ai_analysis"):
                        st.markdown("#### üß† AI Analysis")
                        st.markdown(f'<div class="recommendation-box">{analysis["ai_analysis"]}</div>', unsafe_allow_html=True)
                    
                    # Strategic Recommendations (improved formatting)
                    st.markdown("#### üöÄ Strategic Recommendations")
                    st.markdown(f'<div class="recommendation-box">{analysis["recommendations"]}</div>', unsafe_allow_html=True)
                    
                    # Customer Success Stories (improved variety)
                    st.markdown("#### üéØ Relevant Customer Success Stories")
                    stories = get_relevant_stories(analysis["platforms"])
                    
                    for story in stories:
                        st.markdown(f"""
                        <div class="success-story">
                        <h4>{story["title"]}</h4>
                        <p><strong>Results:</strong> {story["metrics"]}</p>
                        <p><em>"{story["quote"]}"</em></p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Specific Next Steps (improved)
                    st.markdown("#### üìã Recommended Next Steps")
                    next_steps = generate_next_steps(analysis["platforms"], customer_content)
                    for i, step in enumerate(next_steps, 1):
                        st.markdown(f"{i}. {step}")
                    
            else:
                st.warning("Please provide customer content to analyze.")
    
    elif page == "‚ÑπÔ∏è About":
        st.markdown("### About ML Workload Discovery Assistant")
        
        st.markdown("""
        This application helps **Snowflake Account Executives** analyze customer ML workloads and generate strategic recommendations using **Snowflake Cortex AI**.
        
        #### üîß **Current Capabilities:**
        - ‚úÖ **Document Upload & Parsing** using Snowflake PARSE_DOCUMENT (PDF, TXT, DOCX)
        - ‚úÖ **Multi-Platform Detection** (AWS SageMaker, Databricks, Azure ML, Excel/Manual, etc.)
        - ‚úÖ **Enhanced AI Analysis** using Cortex AI COMPLETE and SUMMARIZE
        - ‚úÖ **Customer Success Stories** from real Snowflake ML wins (18 reference stories)
        - ‚úÖ **Competitive Intelligence** based on actual AE training materials
        - ‚úÖ **Specific Next Steps** tailored to customer situation and timeline
        
        #### üìä **Reference Knowledge Base:**
        Built from actual Snowflake content including:
        - **18 real customer success stories** with specific metrics and quotes
        - **"AI & ML 101 for AEs"** training materials with competitive analysis
        - **Platform-specific positioning** for SageMaker, Databricks, and Azure ML
        
        #### üéØ **Perfect For:**
        - Customer discovery call analysis
        - Competitive displacement opportunities  
        - Strategic account planning and positioning
        - POC opportunity identification and scoping
        
        #### ‚ö†Ô∏è **Current Limitations:**
        - **Competitive analysis** currently optimized for AWS SageMaker, Databricks, and Azure ML
        - **Document parsing** requires Snowflake PARSE_DOCUMENT permissions
        - **Analysis quality** depends on detail level in customer content
        
        ---
        
        **This application uses the comprehensive reference knowledge you provided, including all customer stories and competitive intelligence from the "AI & ML 101 for AEs" materials.**
        """)

if __name__ == "__main__":
    main() 